parameters:
  - name: environment
    default: ""
  - name: databricks_host
    default: ""
  - name: databricks_token
    default: ""
{{- if eq .migrate "yes"}}
  - name: databricks_cluster
    default: ""
{{- end}}
  - name: project_id
    default: ""
  - name: inegration_build_name
    default: ""
jobs:
  - job: job_application_deployment
    displayName: "Job - Deployment"
    steps:
      # Get secrets from KeyVault
      - template: ../tasks/task_keyvault_secrets.yml
      - task: UsePythonVersion@0
        displayName: "Task - Set Python version"
        inputs:
          versionSpec: $(default_python_version)
          addToPath: true
      - task: DownloadPipelineArtifact@2
        name: task_download_artifact
        displayName: "Task - Download artifact"
        inputs:
          buildType: "specific"
          project: {{`${{parameters.project_id}}`}}
          definition: "$(resources.pipeline.{{`${{parameters.inegration_build_name}}`}}.pipelineID)"
          buildVersionToDownload: "specific"
          pipelineId: "$(resources.pipeline.{{`${{parameters.inegration_build_name}}`}}.RunId)"
          itemPattern: "**/*/app-$(resources.pipeline.{{`${{parameters.inegration_build_name}}`}}.RunId).zip"
          targetPath: "$(Pipeline.Workspace)"
      - task: ExtractFiles@1
        name: task_extract_artifact_files
        displayName: "Task - Extracting artifact files"
        inputs:
          archiveFilePatterns: "$(Pipeline.Workspace)/artifact/app-$(resources.pipeline.{{`${{parameters.inegration_build_name}}`}}.RunId).zip"
          destinationFolder: "$(Pipeline.Workspace)/bundle"
          cleanDestinationFolder: true
          overwriteExistingFiles: false
      # Can be used on the agent with no Databricks installed;
      # PG agents, where the pipeline runs has pre-installed Databricks CLI
      # - task: PowerShell@2
      #   name: task_dab_cli
      #   displayName: "Task - Install Databricks CLI"
      #   inputs:
      #     pwsh: true
      #     targetType: "inline"
      #     script: |
      #       curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
      #     pwsh: true
      #     workingDirectory: "$(Pipeline.Workspace)"
{{- if eq .developer_workflow "vscode-python"}}
      - task: PowerShell@2
        name: task_install_tools
        displayName: "Task - Install tools"
        inputs:
          pwsh: true
          targetType: "inline"
          script: |
            python -m venv .venv
            & "$(System.DefaultWorkingDirectory)/.venv/bin/Activate.ps1"
            pip install poetry
            poetry config http-basic.pg_jfrog "$(jFrogUsername)" "$(jFrogToken)" # You must store username and secret in Azure Library or KeyVault
            poetry install
{{- end}}
      - task: PowerShell@2
        name: task_dab_validate
        displayName: "Task - Validate DAB ({{`${{ parameters.environment }}`}})"
        inputs:
          pwsh: true
          targetType: "inline"
          script: |
{{- if eq .developer_workflow "vscode-python"}}
            & "$(System.DefaultWorkingDirectory)/.venv/bin/Activate.ps1"
{{- end}}
            Write-Host "[INFO] Environment: {{`${{ parameters.environment }}"`}}
            databricks bundle validate -t {{`${{ parameters.environment }}`}}
          workingDirectory: "$(Pipeline.Workspace)/bundle"
        env:
          DATABRICKS_HOST: {{`${{parameters.databricks_host}}`}}
          DATABRICKS_TOKEN: $(databricks-token) # from KeyVault
{{- if eq .migrate "yes"}}
      - task: AzureCLI@2
        displayName: "Task - Migrate Schema ({{`${{ parameters.environment }}`}})"
        inputs:
          scriptType: pscore
          azureSubscription: $(azure_subscription)
          scriptLocation: inlineScript
          inlineScript: |
            Write-Host "[INFO] Migrating schema for {{`${{ parameters.environment }}`}}"
            {{- if eq .developer_workflow "ui-notebook" }}
            databricks bundle run -t {{`${{ parameters.environment }}`}} migrate_{{.project_name}}_schema
            {{- end}}
            {{- if eq .developer_workflow "vscode-python" }}
            & "$(System.DefaultWorkingDirectory)/.venv/bin/Activate.ps1"
            poetry run migrate
            {{- end}}
          addSpnToEnvironment: true
        env:
          ENVIRONMENT: {{`${{ parameters.environment }}`}}
          DATABRICKS_HOST: {{`${{parameters.databricks_host}}`}}
          DATABRICKS_TOKEN: $(databricks-token) # from KeyVault
          DATABRICKS_CLUSTER_ID: {{`${{ parameters.databricks_cluster }}`}}
{{- end}}
      - task: PowerShell@2
        name: task_dab_deploy
        displayName: "Task - Deploy DAB ({{`${{ parameters.environment }}`}})"
        inputs:
          pwsh: true
          targetType: "inline"
          script: |
{{- if eq .developer_workflow "vscode-python"}}
            & "$(System.DefaultWorkingDirectory)/.venv/bin/Activate.ps1"
{{- end}}
            Write-Host "[INFO] Environment: {{`${{ parameters.environment }}"`}}
            databricks bundle deploy -t {{`${{ parameters.environment }}`}}
          workingDirectory: "$(Pipeline.Workspace)/bundle"
        env:
          DATABRICKS_HOST: {{`${{parameters.databricks_host}}`}}
          DATABRICKS_TOKEN: $(databricks-token) # from KeyVault
